#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯”è¾ƒä¸åŒæ ¼å¼çš„PDFè§£æç»“æœï¼Œè¯„ä¼°AIç†è§£èƒ½åŠ›
"""

import os
import re
from typing import Dict, List, Tuple

def analyze_text_structure(text: str, format_name: str) -> Dict:
    """åˆ†ææ–‡æœ¬ç»“æ„ç‰¹å¾"""
    analysis = {
        "format": format_name,
        "total_length": len(text),
        "lines": len(text.split('\n')),
        "tables": 0,
        "headers": 0,
        "position_tags": 0,
        "key_phrases": {},
        "structure_score": 0
    }
    
    # ç»Ÿè®¡è¡¨æ ¼æ•°é‡
    table_patterns = [
        r'\|.*\|',  # Markdownè¡¨æ ¼
        r'```\n\|.*\|',  # ä»£ç å—ä¸­çš„è¡¨æ ¼
        r'<pos.*?>.*?</pos>',  # ä½ç½®æ ‡ç­¾
    ]
    
    for pattern in table_patterns:
        matches = re.findall(pattern, text, re.MULTILINE | re.DOTALL)
        analysis["tables"] += len(matches)
    
    # ç»Ÿè®¡æ ‡é¢˜æ•°é‡
    header_patterns = [
        r'^#{1,3}\s+.*$',  # Markdownæ ‡é¢˜
        r'^###\s+.*$',  # ä¸‰çº§æ ‡é¢˜
    ]
    
    for pattern in header_patterns:
        matches = re.findall(pattern, text, re.MULTILINE)
        analysis["headers"] += len(matches)
    
    # ç»Ÿè®¡ä½ç½®æ ‡ç­¾æ•°é‡
    pos_tags = re.findall(r'<pos.*?>.*?</pos>', text)
    analysis["position_tags"] = len(pos_tags)
    
    # æ£€æŸ¥å…³é”®çŸ­è¯­
    key_phrases = [
        "åŸºé‡‘æ€»å€¼",
        "æµ·å¤–åŸºé‡‘èµ„æ–™", 
        "æŠ•èµ„ç›®æ ‡",
        "ç®¡ç†è´¹",
        "é£é™©æ°´å¹³",
        "è‚¡ä»½ç±»åˆ«",
        "ISIN",
        "å½­åšä»£ç "
    ]
    
    for phrase in key_phrases:
        count = text.count(phrase)
        analysis["key_phrases"][phrase] = count
    
    # è®¡ç®—ç»“æ„è¯„åˆ†
    analysis["structure_score"] = (
        analysis["tables"] * 10 +  # è¡¨æ ¼æƒé‡é«˜
        analysis["headers"] * 5 +   # æ ‡é¢˜æƒé‡ä¸­ç­‰
        analysis["position_tags"] * 2 +  # ä½ç½®ä¿¡æ¯æƒé‡è¾ƒä½
        len([v for v in analysis["key_phrases"].values() if v > 0]) * 3  # å…³é”®ä¿¡æ¯æƒé‡
    )
    
    return analysis

def extract_sample_content(text: str, format_name: str, max_lines: int = 20) -> str:
    """æå–æ ·æœ¬å†…å®¹ç”¨äºå±•ç¤º"""
    lines = text.split('\n')
    sample_lines = lines[:max_lines]
    
    sample = f"\n=== {format_name} æ ·æœ¬å†…å®¹ ===\n"
    sample += "\n".join(sample_lines)
    
    if len(lines) > max_lines:
        sample += f"\n... (è¿˜æœ‰ {len(lines) - max_lines} è¡Œ)"
    
    return sample

def compare_formats():
    """æ¯”è¾ƒä¸åŒæ ¼å¼çš„è§£æç»“æœ"""
    
    # æ–‡ä»¶è·¯å¾„
    files = {
        "PyMuPDFåŸå§‹è¾“å‡º": "pymupdf_extraction_result.txt",
        "ç»“æ„åŒ–Markdown": "python_service/file/å®‰è”ç¾å…ƒ_converted.md", 
        "å¸¦ä½ç½®ä¿¡æ¯Markdown": "python_service/file/å®‰è”ç¾å…ƒ_with_positions.md"
    }
    
    results = {}
    samples = {}
    
    print("ğŸ” æ­£åœ¨åˆ†æä¸åŒæ ¼å¼çš„PDFè§£æç»“æœ...\n")
    
    for format_name, file_path in files.items():
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # åˆ†æç»“æ„
                analysis = analyze_text_structure(content, format_name)
                results[format_name] = analysis
                
                # æå–æ ·æœ¬
                samples[format_name] = extract_sample_content(content, format_name)
                
                print(f"âœ… {format_name}: åˆ†æå®Œæˆ")
                
            except Exception as e:
                print(f"âŒ {format_name}: åˆ†æå¤±è´¥ - {e}")
        else:
            print(f"âš ï¸  {format_name}: æ–‡ä»¶ä¸å­˜åœ¨ - {file_path}")
    
    print("\n" + "="*80)
    print("ğŸ“Š æ ¼å¼å¯¹æ¯”åˆ†æç»“æœ")
    print("="*80)
    
    # æŒ‰ç»“æ„è¯„åˆ†æ’åº
    sorted_results = sorted(results.items(), key=lambda x: x[1]["structure_score"], reverse=True)
    
    for i, (format_name, analysis) in enumerate(sorted_results, 1):
        print(f"\nğŸ† ç¬¬{i}å: {format_name}")
        print(f"   ç»“æ„è¯„åˆ†: {analysis['structure_score']}")
        print(f"   æ€»é•¿åº¦: {analysis['total_length']:,} å­—ç¬¦")
        print(f"   è¡Œæ•°: {analysis['lines']:,}")
        print(f"   è¡¨æ ¼: {analysis['tables']}")
        print(f"   æ ‡é¢˜: {analysis['headers']}")
        print(f"   ä½ç½®æ ‡ç­¾: {analysis['position_tags']}")
        
        print(f"   å…³é”®çŸ­è¯­è¦†ç›–:")
        for phrase, count in analysis["key_phrases"].items():
            status = "âœ…" if count > 0 else "âŒ"
            print(f"     {status} {phrase}: {count}")
    
    print("\n" + "="*80)
    print("ğŸ“ å„æ ¼å¼æ ·æœ¬å†…å®¹")
    print("="*80)
    
    for format_name, sample in samples.items():
        print(sample)
        print("\n" + "-"*60 + "\n")
    
    # æ¨èåˆ†æ
    print("="*80)
    print("ğŸ’¡ AIç†è§£èƒ½åŠ›è¯„ä¼°ä¸æ¨è")
    print("="*80)
    
    best_format = sorted_results[0][0]
    print(f"ğŸ¯ æ¨èæ ¼å¼: {best_format}")
    
    if "ç»“æ„åŒ–Markdown" in best_format:
        print("   ä¼˜åŠ¿:")
        print("   - ä¿æŒäº†è¡¨æ ¼ç»“æ„ï¼ŒAIæ›´å®¹æ˜“ç†è§£æ•°æ®å…³ç³»")
        print("   - æ ‡é¢˜å±‚æ¬¡æ¸…æ™°ï¼Œä¾¿äºç†è§£æ–‡æ¡£ç»“æ„")
        print("   - å»é™¤äº†å†—ä½™çš„ä½ç½®ä¿¡æ¯ï¼Œæ–‡æœ¬æ›´æ¸…æ´")
        print("   - é€‚åˆè¯­ä¹‰æœç´¢å’Œé—®ç­”")
        
    elif "å¸¦ä½ç½®ä¿¡æ¯Markdown" in best_format:
        print("   ä¼˜åŠ¿:")
        print("   - ä¿ç•™äº†å®Œæ•´çš„ä½ç½®ä¿¡æ¯ï¼Œä¾¿äºé«˜äº®æ˜¾ç¤º")
        print("   - å­—ä½“å’Œå¤§å°ä¿¡æ¯å®Œæ•´")
        print("   - é€‚åˆéœ€è¦ç²¾ç¡®å®šä½çš„åº”ç”¨åœºæ™¯")
        print("   - ä½†ä½ç½®æ ‡ç­¾å¯èƒ½å½±å“AIç†è§£")
        
    elif "PyMuPDFåŸå§‹è¾“å‡º" in best_format:
        print("   ä¼˜åŠ¿:")
        print("   - åŸå§‹æ–‡æœ¬ä¿¡æ¯å®Œæ•´")
        print("   - ä½†ç¼ºä¹ç»“æ„åŒ–ä¿¡æ¯")
        print("   - è¡¨æ ¼ç»“æ„ä¸æ¸…æ™°")
        print("   - AIç†è§£éš¾åº¦è¾ƒé«˜")
    
    print("\nğŸ”§ å»ºè®®:")
    print("1. å¯¹äºRAGé—®ç­”ç³»ç»Ÿï¼Œæ¨èä½¿ç”¨ç»“æ„åŒ–Markdown")
    print("2. å¯¹äºéœ€è¦ç²¾ç¡®å®šä½çš„åº”ç”¨ï¼Œå¯ä»¥ç»“åˆä¸¤ç§æ ¼å¼")
    print("3. å¯ä»¥è€ƒè™‘åœ¨ç»“æ„åŒ–Markdownä¸­æ·»åŠ å…³é”®ä½ç½®ä¿¡æ¯")

if __name__ == "__main__":
    compare_formats()
